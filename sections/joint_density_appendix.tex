\section{Joint Density Derivation }

\subsection{Proof of Lemma~\ref{lem: joint density}}\label{subsec: joint density derivation}

In this section we want to derive the joint density of \((\nabla^2\rf,\rf):=
(\nabla^2\rf(0), \rf(0))\). As \(\partial_{ij}\rf\) are limits of differences
of multivariate normal random variables, this is a centered multivariate normal
random vector. We therefore only need to consider the covariance. Additionally
we know \(\partial_{ij}\rf = \partial_{ji}\rf\), so we are only interested
in \(((\partial_{ij}\rf)_{i\le j}, \rf)\).

As for the covariances, we have \fxnote{reference}
\begin{align*}
	\Cov(\phi,\phi) &= \dimension \sqC(0)\\
	\Cov(\partial_{ij}\phi,\phi) &= \delta_{ij} \sqC'(0)\\
	\Cov(\partial_{ij}\phi, \partial_{kl}\phi) &= \frac{\sqC''(0)}\dimension
	[\delta_{ij}\delta_{kl} + \delta_{ik}\delta_{jl} + \delta_{il}\delta_{kj}].
\end{align*}
In particular for \(i<j\), we have
\[
	\Cov(\partial_{ij}\phi, \phi) = 0,
\]
and also
\[
	\Cov(\partial_{ij}\phi, \partial_{kl}\phi) = \frac{\sqC''(0)}\dimension
	[\delta_{ik}\delta_{jl} + \underbrace{\delta_{il}\delta_{kj}}_{=0}],
\]
because \(\delta_{il}\delta_{kj}=1\) would imply \(i < j = k \le l = i\), which
is a contradiction. So this covariance is only non-zero, if \(i=k\) and \(j=l\),
i.e. \(\partial_{ij}\phi\) for \(i<j\) has covariance zero with all other terms.
As we are in the multivariate Gaussian case, this also implies independence.
Shifting all these independent mixed derivatives to the end, our covariance
matrix looks like
\[
	\Sigma := \Cov((\partial_{ii}\phi)_{i\le\dimension}, \phi, (\partial_{ij}\phi)_{i<j})
	= \begin{pmatrix}
		B & 0\\
		0 & \frac{\sqC''(0)}{\dimension}\identity
	\end{pmatrix}
\]
with
\[
	B = \begin{pmatrix}
		3\frac{\sqC''(0)}\dimension &  \cdots & \frac{\sqC''(0)}\dimension
		& \sqC'(0) \\
		\vdots & \ddots &\vdots & \vdots \\
		\frac{\sqC''(0)}\dimension & \cdots &  3 \frac{\sqC''(0)}\dimension & \sqC'(0)\\
		\sqC'(0)	& \cdots & \sqC'(0) & \dimension \sqC(0)
	\end{pmatrix}
	=: \begin{pmatrix}
		\Sigma_\partial & b \\
		b^T & d
	\end{pmatrix}.
\]
Inverting \(\Sigma\) is easy, if we can invert \(B\). If we can invert the
covariance of partial derivatives \(\Sigma_\partial\), we have
\[
	B^{-1} = \frac1{d- b^T \Sigma_\partial^{-1}b}\begin{pmatrix}
		( d- b^T \Sigma_\partial^{-1}b )\Sigma_\partial^{-1}
		+ \Sigma_\partial^{-1}b b^T \Sigma_\partial^{-1}
		& -\Sigma_\partial^{-1} b\\
		-b^T\Sigma_\partial ^{-1} &  1
	\end{pmatrix},
\]
as one can verify by calculating \(BB^{-1}\). As \(\Sigma_\partial\) is of the form
\[
	\Sigma_\partial=\frac{\sqC''(0)}{\dimension}[2\identity + \ones\ones^T]
\]
with \(\ones=(1,\dots,1)^T\in\real^\dimension\), we can use the Sherman-Morrison
formula.

\begin{lemma}[Sherman-Morrison Formula]
	Let \(A\) be an invertible matrix, \(u,v\in\real^\dimension\) column vectors.
	Then \(A+ uv^T\) is invertible iff \(1+v^T A^{-1}u \neq 0\), and if that is
	the case, we have
	\[
		(A+uv^T) = A^{-1} - \frac{A^{-1}u v^T A^{-1}}{1+v^T A^{-1}u}.
	\]
\end{lemma}
\begin{proof}
	\fxnote{find reference (or reproduce wikipedia proof)}
\end{proof}

The application of this formula results in
\begin{equation}\label{eq: sigma_partial inverse}
	\Sigma_\partial^{-1}
	= \frac{\dimension}{\sqC''(0)}\left[
		\tfrac12\identity - \frac{\tfrac14\ones\ones^T}{1+\tfrac12\ones^T\ones}
	\right]
	= \frac{\dimension}{2\sqC''(0)}\left[
		\identity - \frac{1}{2+\dimension}\ones\ones^T
	\right].
\end{equation}
To determine \(B^{-1}\), we first define
\begin{align*}
	q := d - b^T \Sigma_\partial^{-1}b
	&= \dimension\sqC(0) - \tfrac{\dimension\sqC'(0)^2}{2\sqC''(0)}\ones^T
	[\identity-\tfrac1{2+\dimension}\ones\ones^T]\ones\\
	&= \dimension\left[
		\sqC(0) - \tfrac{\sqC'(0)^2}{2\sqC''(0)}
		\dimension( 1-\tfrac{\dimension}{2+\dimension} )
	\right]\\
	&= \dimension\left[
		\sqC(0) - \tfrac{\sqC'(0)^2}{\sqC''(0)}
		\tfrac{\dimension}{2+\dimension}
	\right],
\end{align*}
and then calculate
\begin{equation}\label{eq: definition of c=sigma_partial^{-1} b}
	c:=\Sigma_\partial^{-1}b
	= \tfrac{\sqC'(0)}{2\sqC''(0)}( 1 - \tfrac{\dimension}{2+\dimension} )\ones
	= \tfrac{\sqC'(0)}{\sqC''(0)}\tfrac{1}{2+\dimension}\ones.
\end{equation}
Therefore we have
\begin{equation}\label{eq: inv B split}
	B^{-1} = \begin{pmatrix}
		\Sigma_\partial^{-1}	+ \frac{cc^T}{q} & - \frac{c}{q}\\
		-\frac{c^T}{q} & \frac1q
	\end{pmatrix}
	= \begin{pmatrix}
		\Sigma_\partial^{-1} & 0 \\
		0 & 0
	\end{pmatrix}
	+ \tfrac1q \begin{pmatrix}
		cc^T & -c\\
		-c^T & 1
	\end{pmatrix}.
\end{equation}

Let us take a step back now. We want to calculate
\begin{equation*}
	p(H, \phi)
	=C_\dimension\exp\left(
		-\tfrac12
		( H_{ii},\phi, H_{ij} )\Sigma^{-1}
		\begin{pmatrix}
			H_{ii}\\
			\phi\\
			H_{ij}
		\end{pmatrix}
	\right)
\end{equation*}
where we abbreviate for readability \((H_{ii}, \phi, H_{ij})= ((H_{ii})_{i\le
\dimension}, \phi, (H_{ij})_{i<j})\) and define
\begin{align*}
	C_\dimension &:= \left(2\pi\det(\Sigma)\right)^{-n(\dimension)/2}\\
	n(\dimension) &:= 1 + \tfrac{\dimension(\dimension+1)}{2}.
\end{align*}
Looking at just the exponent we have
\begin{align*}
		\tfrac12
		( H_{ii},\phi, H_{ij} )\Sigma^{-1}
		\begin{pmatrix}
			H_{ii}\\
			\phi\\
			H_{ij}
		\end{pmatrix}
		&= 
		\tfrac12
		( H_{ii},\phi, H_{ij} )\begin{pmatrix}
			B^{-1} & 0\\
			0 & \tfrac{\dimension}{\sqC''(0)}\identity
		\end{pmatrix}
		\begin{pmatrix}
			H_{ii}\\
			\phi\\
			H_{ij}
		\end{pmatrix}\\
		&= \tfrac12(H_{ii},\phi)B^{-1}\begin{pmatrix}
			H_{ii}\\ \phi
		\end{pmatrix}
		+ \underbrace{\tfrac{\dimension}{2\sqC''(0)}\| (H_{ij})_{i<j}\|^2}_{
			=\tfrac{\dimension}{4\sqC''(0)}\| (H_{ij})_{i\neq j}\|^2.
		}
\end{align*}
Now if we inspect \(B^{-1}\), we notice that \(H_{ii}\) will in most cases be paired
with \(\ones\) which results in the trace \(\trace{H}\). Only inside \(\Sigma_\partial^{-1}\)
there is another identity matrix. This results in another norm, with the
same coefficient \(\frac{\dimension}{4\sqC''(0)}\) (cf. \eqref{eq: sigma_partial
inverse}) after collecting the global \(\tfrac12\) from the exponent. More
precisely
\[
	H_{ii} \Sigma_\partial^{-1} H_{ii}
	= \frac{\dimension}{2\sqC''(0)}
	\left[\|H_{ii}\|^2 - \tfrac{(\trace H)^2}{2+\dimension}\right]
\]
Putting the norms together we get
\begin{align*}
	\|(H_{ij})\|^2 = \sum_{i,j=1}^\dimension H_{ij}^2
	= \sum_{i=1}^\dimension \underbrace{\sum_{j=1}^\dimension H_{ij}H_{ji}}_{(H^2)_{ii}}
	= \trace(H^2).
\end{align*}
We therefore end up with a formula utilizing only \(\trace H\) and \((\trace H)^2\).
So if we recall \eqref{eq: inv B split}, we get
\begin{align*}
		&\tfrac12
		( H_{ii},\phi, H_{ij} )\Sigma^{-1}
		\begin{pmatrix}
			H_{ii}\\
			\phi\\
			H_{ij}
		\end{pmatrix}\\
		&= \tfrac{\dimension}{4\sqC''(0)}\left[
			\trace H^2 - \tfrac{(\trace H)^2}{2+\dimension}
		\right]
		+ \frac1{2q} \underbrace{
			(H_{ii}, \phi)\begin{pmatrix}
			cc^T & -c\\
			-c^T & 1
		\end{pmatrix}
		\begin{pmatrix}
			H_{ii}\\ \phi
		\end{pmatrix}
		}_{
			= \langle H_{ii}, c\rangle^2 - 2\phi \langle H_{ii}, c\rangle + \phi^2
		}\\
		&= \tfrac{\dimension}{4\sqC''(0)}\bigl[
			\trace H^2 - \underbrace{
				\tfrac{(\trace H)^2}{2+\dimension}
				\bigr]
				+ \frac{\langle H_{ii}, c\rangle^2}{2q}
			}_{=:I}
		 	+ \frac{- 2\phi \langle H_{ii}, c\rangle + \phi^2}{2q}
\end{align*}
And if we recall the definition of \(c\) in \eqref{eq: definition of
c=sigma_partial^{-1} b} and the definition of \(q\) which resulted in
\[
	c=\tfrac{\sqC'(0)}{\sqC''(0)}\tfrac{1}{2+\dimension}\ones
	\qquad \text{and} \qquad
	q=\dimension\left[
		\sqC(0) - \tfrac{\sqC'(0)^2}{\sqC''(0)}
		\tfrac{\dimension}{2+\dimension}
	\right],
\]
we immediately get
\[
	\langle c, H_{ii}\rangle = 
	\tfrac{\sqC'(0)}{\sqC''(0)}\tfrac{1}{2+\dimension}\trace H.
\]
Now let us calculate the coefficient of all the squared traces. We have
\begin{align*}
	I &= \left[
		\frac{1}{4\sqC''(0)}\frac{\dimension}{2+\dimension} + 
		\frac{
			\left(\tfrac{\sqC'(0)}{\sqC''(0)}\tfrac{1}{2+\dimension}\right)^2
		}{2q}
	\right](\trace H)^2\\
	&= \frac{1}{4\sqC''(0)}
	\left[
		\frac{\dimension}{2+\dimension} + 
		2\frac{\sqC'(0)^2}{\sqC''(0)}\frac{\frac1{(2+N)^2}}{q}
	\right](\trace H)^2
\end{align*}